# Phase 2: Memory64 & Large Models - ULTRATHINK üß†

> **Deep Analysis for Production-Ready Large Model Inference in WASM**
>
> Target: 7B-70B parameter models, <100ms latency, cross-platform, offline-first

---

## üéØ Mission Statement

Enable production-grade inference of large language models (7B-70B parameters) in WebAssembly across:
- **Browsers** (Chrome, Firefox, Safari with Memory64 support)
- **Server runtimes** (Wasmer, Wasmtime, WasmEdge)
- **Edge devices** (Offline, resource-constrained)
- **Cloud functions** (AWS Lambda, Cloudflare Workers with WASM)

**Core Constraint**: WASM's 4GB memory limit (32-bit) must be overcome.

---

## üìö Part 1: WASM Memory Evolution & Capabilities

### 1.1 Standard WASM Memory (Current Limitation)

**Architecture**:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   WASM Linear Memory (32-bit)  ‚îÇ
‚îÇ   Max: 4GB (2^32 bytes)        ‚îÇ
‚îÇ                                 ‚îÇ
‚îÇ   Addressing: i32 pointers     ‚îÇ
‚îÇ   Pages: 64KB chunks           ‚îÇ
‚îÇ   Max pages: 65,536            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Model Size Limits**:
- 7B model (Q4_K_M): ~4.2GB ‚ùå **Won't fit**
- 3B model (Q4_K_M): ~1.8GB ‚úÖ **Fits**
- 13B model: ~7.8GB ‚ùå **Won't fit**

**Problem**: Most production LLMs exceed 4GB even when quantized.

---

### 1.2 Memory64 Extension (WASM 3.0)

**Specification**: https://github.com/WebAssembly/memory64

**Architecture**:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   WASM Linear Memory (64-bit)  ‚îÇ
‚îÇ   Max: 16 EXABYTES (2^64)      ‚îÇ
‚îÇ                                 ‚îÇ
‚îÇ   Addressing: i64 pointers     ‚îÇ
‚îÇ   Pages: 64KB chunks           ‚îÇ
‚îÇ   Max pages: 2^48              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Key Features**:
1. **64-bit addressing**: `i64.load`, `i64.store` instructions
2. **Backward compatible**: Modules can use i32 OR i64 memory
3. **No performance penalty**: Modern CPUs natively 64-bit
4. **Explicit opt-in**: `(memory (i64 <min> <max>))` in WAT

**Runtime Support** (as of 2025):

| Runtime | Memory64 | Status | Notes |
|---------|----------|--------|-------|
| **Wasmtime** | ‚úÖ Yes | Stable | v8.0+ full support |
| **Wasmer** | ‚úÖ Yes | Stable | v3.0+ full support |
| **WasmEdge** | ‚úÖ Yes | Stable | v0.11+ support |
| **Node.js (V8)** | ‚úÖ Yes | Experimental | --experimental-wasm-memory64 |
| **Chrome** | üöß Partial | Flag required | chrome://flags/#enable-experimental-webassembly-features |
| **Firefox** | üöß Partial | Nightly only | about:config wasm_memory64 |
| **Safari** | ‚ùå No | Not yet | Tracking bug filed |

**Conclusion**: Memory64 is **production-ready for server/edge**, **experimental for browsers**.

---

### 1.3 Multi-Memory Proposal

**Specification**: https://github.com/WebAssembly/multi-memory

**Concept**: Multiple independent linear memories in a single WASM module.

**Architecture**:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  WASM Module with Multi-Memory          ‚îÇ
‚îÇ                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ  ‚îÇ Memory 0   ‚îÇ  ‚îÇ Memory 1   ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ (Weights)  ‚îÇ  ‚îÇ (KV Cache) ‚îÇ  ...    ‚îÇ
‚îÇ  ‚îÇ 4GB        ‚îÇ  ‚îÇ 4GB        ‚îÇ         ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ                                          ‚îÇ
‚îÇ  Total addressable: N √ó 4GB             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Use Cases**:
1. **Shard model weights** across memories (Memory 0-7 for 32GB model)
2. **Separate KV cache** from weights (isolation, easier management)
3. **Page in/out** memories dynamically (swap to disk for huge models)
4. **Security isolation** (untrusted code can't access secure memory)

**Runtime Support**:

| Runtime | Multi-Memory | Status |
|---------|--------------|--------|
| **Wasmtime** | ‚úÖ Yes | Stable since v3.0 |
| **Wasmer** | ‚úÖ Yes | Stable since v3.2 |
| **WasmEdge** | ‚úÖ Yes | v0.12+ |
| **Browsers** | ‚ùå No | Not yet implemented |

**Key Limitation**: Multi-memory is **server/edge only** for now.

---

### 1.4 Combining Memory64 + Multi-Memory

**The Ultimate Solution**:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  WASM Module with Multi-Memory64                ‚îÇ
‚îÇ                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ  ‚îÇ  Memory 0    ‚îÇ  ‚îÇ  Memory 1    ‚îÇ            ‚îÇ
‚îÇ  ‚îÇ  (i64, 16GB) ‚îÇ  ‚îÇ  (i64, 16GB) ‚îÇ   ...      ‚îÇ
‚îÇ  ‚îÇ  Layers 0-15 ‚îÇ  ‚îÇ  Layers 16-31‚îÇ            ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îÇ                                                  ‚îÇ
‚îÇ  Total: 70B model (64GB) across 4 memories     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Capabilities**:
- ‚úÖ **Single memory64**: Up to 16GB per memory (practical OS limit)
- ‚úÖ **4 memories √ó 16GB**: 64GB total (70B Q4 model!)
- ‚úÖ **8 memories √ó 16GB**: 128GB (405B model possible)

**Support Matrix**:

| Platform | Memory64 | Multi-Memory | Combined |
|----------|----------|--------------|----------|
| **Wasmtime** | ‚úÖ | ‚úÖ | ‚úÖ **READY** |
| **Wasmer** | ‚úÖ | ‚úÖ | ‚úÖ **READY** |
| **Chrome (flag)** | üöß | ‚ùå | ‚ùå |
| **Firefox (nightly)** | üöß | ‚ùå | ‚ùå |

**Conclusion**: **Server/edge deployment with Wasmtime/Wasmer is ready NOW for 70B+ models.**

---

## üèóÔ∏è Part 2: Architecture Design

### 2.1 Deployment Tiers

We need **3 different builds** for different platforms:

#### **Tier 1: Browser (Standard Memory) - 3B models max**
```rust
// Target: wasm32-unknown-unknown
// Memory: Single i32 linear memory (4GB max)
// Models: Up to 3B parameters (Q4_K_M)
#[cfg(target_arch = "wasm32")]
pub fn create_model() -> Model {
    // Standard memory allocations
    let weights = vec![0f32; model_size];
    Model { weights }
}
```

**Limitations**:
- ‚ùå No Memory64
- ‚ùå No Multi-Memory
- ‚úÖ Works in all browsers TODAY

**Use Cases**: Demo apps, small assistants, edge inference

---

#### **Tier 2: Server (Memory64) - 13B models**
```rust
// Target: wasm64-unknown-unknown (experimental)
// Memory: Single i64 linear memory (16GB practical limit)
// Models: Up to 13B parameters (Q4_K_M)

#[cfg(target_feature = "memory64")]
pub fn create_large_model() -> Result<Model> {
    // Allocate >4GB in single memory
    let weights_ptr = allocate_memory64(8_000_000_000); // 8GB
    Model::from_ptr(weights_ptr)
}
```

**Build**:
```bash
# Rust doesn't have wasm64 target yet, use custom LLVM
wasm-ld --memory64 -o model.wasm model.o
```

**Limitations**:
- ‚úÖ Memory64 supported
- ‚ùå No Multi-Memory
- ‚úÖ Single 16GB allocation (OS limit)

**Use Cases**: API servers, cloud functions, edge inference

---

#### **Tier 3: Server (Memory64 + Multi-Memory) - 70B models**
```rust
// Target: wasm64-unknown-unknown with multi-memory feature
// Memory: Multiple i64 linear memories
// Models: 70B+ parameters

pub struct ShardedModel {
    memories: Vec<MemoryHandle>,  // 4-8 separate memories
    layer_map: HashMap<LayerId, (MemoryId, Offset)>,
}

impl ShardedModel {
    pub fn load_70b(path: &Path) -> Result<Self> {
        let mut memories = Vec::new();

        // Create 4 memories of 16GB each = 64GB total
        for i in 0..4 {
            memories.push(Memory::new(i64, 16 * GB)?);
        }

        // Load layers across memories
        // Layers 0-19  -> Memory 0
        // Layers 20-39 -> Memory 1
        // Layers 40-59 -> Memory 2
        // Layers 60-79 -> Memory 3

        Ok(ShardedModel { memories, layer_map })
    }

    pub fn forward(&self, tokens: &[u32]) -> Result<Tensor> {
        let mut x = self.embed(tokens)?;

        for layer_id in 0..80 {
            let (mem_id, offset) = self.layer_map[&layer_id];
            let layer_weights = self.load_from_memory(mem_id, offset)?;
            x = self.transformer_block(x, layer_weights)?;
        }

        self.lm_head(x)
    }
}
```

**Capabilities**:
- ‚úÖ Memory64 addressing
- ‚úÖ Multi-memory sharding
- ‚úÖ 64GB+ models (70B parameters)
- ‚úÖ Dynamic memory paging possible

**Use Cases**: Production LLM serving, offline AI, edge clusters

---

### 2.2 Memory Sharding Strategies

#### **Strategy A: Layer-based Sharding** (Recommended)

**Concept**: Each transformer layer in one memory block.

```
Memory 0: Embedding + Layers 0-19    (16GB)
Memory 1: Layers 20-39               (16GB)
Memory 2: Layers 40-59               (16GB)
Memory 3: Layers 60-79 + LM Head     (16GB)
```

**Advantages**:
- ‚úÖ Clean boundaries (no layer split across memories)
- ‚úÖ Predictable access patterns (sequential layer execution)
- ‚úÖ Easy to implement
- ‚úÖ Cache-friendly (entire layer in one memory)

**Disadvantages**:
- ‚ö†Ô∏è Imbalanced sizes if layers vary in parameters
- ‚ö†Ô∏è Must cross memory boundary 3 times per forward pass

**Implementation**:
```rust
struct LayerShard {
    memory_id: usize,
    offset: usize,
    size: usize,
}

fn shard_by_layers(model: &ModelConfig, num_memories: usize) -> Vec<LayerShard> {
    let layers_per_memory = model.num_layers / num_memories;
    (0..model.num_layers)
        .map(|layer_id| LayerShard {
            memory_id: layer_id / layers_per_memory,
            offset: calculate_offset(layer_id),
            size: layer_size(layer_id),
        })
        .collect()
}
```

---

#### **Strategy B: Tensor-type Sharding**

**Concept**: Group tensors by type across memories.

```
Memory 0: All Q projections       (12GB)
Memory 1: All K projections       (12GB)
Memory 2: All V projections       (12GB)
Memory 3: All FFN weights         (28GB)
```

**Advantages**:
- ‚úÖ Better balance if tensor types similar size
- ‚úÖ Can optimize memory access per operation type

**Disadvantages**:
- ‚ùå Complex addressing (every layer touches all memories)
- ‚ùå Poor cache locality
- ‚ùå More memory boundary crossings

**Verdict**: ‚ùå **Not recommended** - too complex, worse performance.

---

#### **Strategy C: Hybrid KV-Cache Separation**

**Concept**: Dedicate one memory to KV cache, rest for weights.

```
Memory 0: Model weights (static)   (52GB)
Memory 1: KV cache (dynamic)       (12GB)
```

**Advantages**:
- ‚úÖ KV cache can grow/shrink independently
- ‚úÖ Weights are read-only (can be shared across requests)
- ‚úÖ Easier to implement memory paging (swap KV cache)

**Disadvantages**:
- ‚ö†Ô∏è Still need multi-memory64 for weights if >16GB
- ‚ö†Ô∏è Can't use standard 4GB memory for weights

**Use Case**: **Best for serving with batching** (multiple requests share weights).

---

#### **Strategy D: Memory Paging (Advanced)**

**Concept**: More memories than fit in RAM, page in/out on demand.

```
Disk: 8 memory images (128GB total)
RAM:  4 active memories (64GB)

Layer 0-19:  Load Memory 0 ‚îÄ‚îÄ‚îê
Layer 20-39: Load Memory 1   ‚îÇ Keep in RAM
Layer 40-59: Load Memory 2   ‚îÇ
Layer 60-79: Unload Memory 0, Load Memory 3
```

**Advantages**:
- ‚úÖ Support models larger than RAM (e.g., 405B on 64GB machine)
- ‚úÖ Wasmtime supports memory snapshots (save/restore)

**Disadvantages**:
- ‚ùå Requires disk I/O (slow - 100ms+ per swap)
- ‚ùå Complex state management
- ‚ùå Only viable for high-latency use cases

**Use Case**: Offline inference where latency >500ms is acceptable.

---

### 2.3 Recommended Production Architecture

**For 70B Model on Wasmtime/Wasmer**:

```rust
pub struct ProductionModel {
    // Memory layout
    weight_memories: [Memory; 4],      // 4 √ó 16GB = 64GB for weights
    kv_cache_memory: Memory,            // 1 √ó 4GB for KV cache

    // Sharding metadata
    layer_shards: HashMap<LayerId, ShardInfo>,

    // Runtime config
    batch_size: usize,
    max_seq_len: usize,
}

impl ProductionModel {
    pub fn new(model_path: &str, runtime: &Runtime) -> Result<Self> {
        // 1. Initialize 4 memory64 instances
        let weight_memories = (0..4)
            .map(|i| runtime.create_memory64(16 * GB))
            .collect::<Result<Vec<_>>>()?;

        // 2. Load GGUF and shard weights by layers
        let gguf = load_gguf(model_path)?;
        let shards = shard_layers_evenly(&gguf, 4);

        for (shard_id, layers) in shards.iter().enumerate() {
            load_layers_to_memory(layers, &weight_memories[shard_id])?;
        }

        // 3. Create KV cache memory (standard i32 for now)
        let kv_cache_memory = runtime.create_memory(4 * GB)?;

        Ok(ProductionModel {
            weight_memories,
            kv_cache_memory,
            layer_shards,
            batch_size: 1,
            max_seq_len: 2048,
        })
    }

    pub fn forward(&mut self, tokens: &[u32]) -> Result<Vec<f32>> {
        let mut hidden_state = self.embed(tokens)?;

        for layer_id in 0..80 {
            // Lookup which memory holds this layer
            let shard = &self.layer_shards[&layer_id];
            let memory = &self.weight_memories[shard.memory_id];

            // Load weights from appropriate memory
            let weights = self.load_layer_weights(memory, shard.offset)?;

            // Execute transformer block
            hidden_state = self.transformer_layer(
                hidden_state,
                weights,
                layer_id,
            )?;
        }

        self.lm_head(hidden_state)
    }
}
```

---

## üöÄ Part 3: Implementation Plan

### Phase 2.1: Memory64 Foundation (Week 1)

**Goal**: Single Memory64 support for 7B-13B models

**Tasks**:
1. **Enable memory64 in build**
   ```bash
   # Add to .cargo/config.toml
   [target.wasm64-unknown-unknown]
   rustflags = ["-C", "target-feature=+memory64"]
   ```

2. **Update allocator to use i64 pointers**
   ```rust
   // crates/wasm-chord-core/src/allocator.rs
   #[cfg(target_feature = "memory64")]
   pub fn allocate(size: usize) -> *mut u8 {
       unsafe { alloc_i64(size as i64) as *mut u8 }
   }
   ```

3. **Test with 7B model**
   - Download Llama-2-7B Q4_K_M (~4.2GB)
   - Load in Wasmtime with memory64
   - Run inference, measure latency

**Deliverables**:
- ‚úÖ Memory64-enabled build
- ‚úÖ 7B model loading test
- ‚úÖ Benchmark vs standard memory (4GB limit workaround)

---

### Phase 2.2: Multi-Memory Sharding (Week 2)

**Goal**: Load 70B model across 4 memories

**Tasks**:
1. **Multi-memory API wrapper**
   ```rust
   // crates/wasm-chord-core/src/multi_memory.rs
   pub struct MultiMemoryManager {
       memories: Vec<Memory>,
   }

   impl MultiMemoryManager {
       pub fn load_tensor(&self, shard_id: usize, offset: usize) -> Tensor {
           self.memories[shard_id].read(offset)
       }
   }
   ```

2. **Layer sharding algorithm**
   ```rust
   fn shard_model(gguf: &GGUF, num_shards: usize) -> Vec<LayerGroup> {
       let layers_per_shard = gguf.num_layers() / num_shards;
       // Evenly distribute layers
   }
   ```

3. **Cross-memory tensor operations**
   - Handle cases where attention spans multiple memories
   - Optimize memory copies

4. **Test with 70B model**
   - Llama-2-70B Q4_K_M (~40GB)
   - Shard across 3 memories (16GB + 16GB + 12GB)
   - Measure inference latency

**Deliverables**:
- ‚úÖ Multi-memory manager
- ‚úÖ Sharding implementation
- ‚úÖ 70B model inference working

---

### Phase 2.3: Fused Kernels (Week 3)

**Goal**: Optimize performance with kernel fusion

**Strategy 1: Dequant + GEMM Fusion**

Currently (slow):
```
1. Dequantize Q4_K weights -> FP32 buffer (4√ó size, slow)
2. GEMM with dequantized weights
3. Free FP32 buffer
```

Fused (fast):
```
1. GEMM with on-the-fly dequantization
   - Load 4-bit weight block
   - Dequantize in registers
   - Multiply with activation
   - No intermediate buffer!
```

**Implementation**:
```rust
// Pseudocode for fused kernel
fn fused_dequant_gemm(
    activations: &[f32],     // Input
    q4_weights: &[u8],       // Quantized weights
    scales: &[f32],          // Per-block scales
    output: &mut [f32],
) {
    for block in q4_weights.chunks(32) {
        // Dequantize block into registers (no allocation!)
        let weights_fp32 = dequantize_inline(block, scales);

        // Multiply-accumulate directly
        for i in 0..activations.len() {
            output[i] += activations[i] * weights_fp32[i];
        }
    }
}
```

**Benefits**:
- ‚úÖ 50-70% faster than separate dequant+GEMM
- ‚úÖ No memory allocation for intermediate buffers
- ‚úÖ Better cache utilization

---

**Strategy 2: WebGPU Compute Shaders (Browser Tier)**

```wgsl
// Fused dequant + GEMM shader
@group(0) @binding(0) var<storage, read> activations: array<f32>;
@group(0) @binding(1) var<storage, read> q4_weights: array<u32>;
@group(0) @binding(2) var<storage, read> scales: array<f32>;
@group(0) @binding(3) var<storage, read_write> output: array<f32>;

@compute @workgroup_size(256)
fn fused_dequant_gemm(@builtin(global_invocation_id) id: vec3<u32>) {
    let idx = id.x;

    // Load quantized weight and dequantize on-the-fly
    let q4_val = q4_weights[idx / 8];
    let shift = (idx % 8) * 4;
    let quant = (q4_val >> shift) & 0xF;
    let weight = f32(quant - 8) * scales[idx / 32];

    // Accumulate
    output[id.y] += activations[idx] * weight;
}
```

**Benefits**:
- ‚úÖ GPU parallelism (100√ó faster than CPU)
- ‚úÖ No CPU-GPU transfer overhead
- ‚úÖ Works in browsers with WebGPU

---

### Phase 2.4: Production Hardening (Week 3)

**Tasks**:
1. **Error handling**
   - OOM detection (memory allocation failures)
   - Graceful degradation (fall back to smaller model)

2. **Benchmarking suite**
   ```bash
   cargo bench --bench memory64 -- --save-baseline phase2
   ```

3. **Documentation**
   - Memory64 setup guide
   - Wasmer/Wasmtime deployment examples
   - Performance tuning guide

4. **CI/CD**
   - Add memory64 test job
   - Test on Wasmtime/Wasmer in CI
   - Validate 7B model loading

**Deliverables**:
- ‚úÖ Production-ready memory64 builds
- ‚úÖ Comprehensive benchmarks
- ‚úÖ Deployment documentation

---

## üìä Part 4: Performance Targets

### 4.1 Latency Goals

| Model | Quantization | Size | Target Latency | Platform |
|-------|--------------|------|----------------|----------|
| **7B** | Q4_K_M | 4.2GB | <100ms/token | Wasmtime (single memory64) |
| **13B** | Q4_K_M | 7.8GB | <200ms/token | Wasmtime (single memory64) |
| **70B** | Q4_K_M | 40GB | <1000ms/token | Wasmtime (4√ó memory) |

### 4.2 Memory Overhead

**Sharding overhead**:
- Layer metadata: ~1MB per 1000 layers (negligible)
- Cross-memory copies: <5% of total memory
- KV cache: Depends on batch size (2GB for batch=32, seq=2048)

**Total overhead**: <10% of model size

### 4.3 Optimization Priorities

1. **Fused dequant+GEMM**: 50-70% speedup (HIGH PRIORITY)
2. **Multi-threading**: 2-4√ó speedup on multi-core (MEDIUM)
3. **SIMD vectorization**: 20-40% speedup on AVX512 (MEDIUM)
4. **WebGPU shaders**: 100√ó speedup vs CPU (HIGH for browser)

---

## üõ†Ô∏è Part 5: Tooling & Runtime Integration

### 5.1 Wasmtime Integration

**Setup**:
```bash
cargo install wasmtime-cli
```

**Loading Memory64 Module**:
```rust
use wasmtime::*;

fn main() -> Result<()> {
    let engine = Engine::default();
    let mut store = Store::new(&engine, ());

    // Load WASM module with memory64
    let module = Module::from_file(&engine, "model.wasm")?;

    // Create memory64 instance (16GB)
    let memory_type = MemoryType::new64(1024, Some(16 * 1024)); // 16GB
    let memory = Memory::new(&mut store, memory_type)?;

    // Instantiate with memory
    let instance = Instance::new(&mut store, &module, &[memory.into()])?;

    // Call inference
    let infer = instance.get_typed_func::<(i32, i32), i32>(&mut store, "infer")?;
    let result = infer.call(&mut store, (prompt_ptr, prompt_len))?;

    Ok(())
}
```

---

### 5.2 Wasmer Integration

**Setup**:
```bash
cargo install wasmer-cli
```

**Multi-Memory Support**:
```rust
use wasmer::*;

fn main() -> Result<()> {
    let store = Store::default();
    let module = Module::from_file(&store, "model.wasm")?;

    // Create multiple memory64 instances
    let mem0 = Memory::new(&store, MemoryType::new(1024, Some(16384), true))?; // 16GB
    let mem1 = Memory::new(&store, MemoryType::new(1024, Some(16384), true))?; // 16GB
    let mem2 = Memory::new(&store, MemoryType::new(1024, Some(16384), true))?; // 16GB

    // Import all memories
    let imports = imports! {
        "env" => {
            "memory0" => mem0,
            "memory1" => mem1,
            "memory2" => mem2,
        }
    };

    let instance = Instance::new(&module, &imports)?;

    Ok(())
}
```

---

### 5.3 Build Configuration

**Cargo.toml**:
```toml
[package]
name = "wasm-chord-memory64"
version = "0.2.0"

[lib]
crate-type = ["cdylib"]

[dependencies]
wasm-chord-core = { path = "../wasm-chord-core" }

[profile.release]
opt-level = 3
lto = "fat"
codegen-units = 1
panic = "abort"

# Enable memory64 feature
[target.wasm64-unknown-unknown]
rustflags = ["-C", "target-feature=+memory64,+bulk-memory,+simd128"]
```

**.cargo/config.toml**:
```toml
[build]
target = "wasm64-unknown-unknown"  # Note: Not official yet, may need custom LLVM

[target.wasm64-unknown-unknown]
runner = "wasmtime run --dir=."
```

---

## üéì Part 6: Best Practices & Pitfalls

### ‚úÖ DO:
1. **Align memory boundaries** to 64KB pages (WASM page size)
2. **Batch operations** to minimize memory boundary crossings
3. **Profile before optimizing** - measure actual bottlenecks
4. **Test on target runtime** (Wasmtime/Wasmer) early
5. **Document memory layout** clearly for debugging

### ‚ùå DON'T:
1. **Mix i32 and i64 pointers** - leads to subtle bugs
2. **Assume browser support** for memory64 (not ready yet)
3. **Over-shard** - too many memories = overhead
4. **Forget KV cache** - can be 20-30% of total memory
5. **Ignore alignment** - misaligned access = crashes

---

## üìà Part 7: Success Metrics

**Phase 2 Complete When**:
- ‚úÖ 7B model loads and infers in Wasmtime (memory64)
- ‚úÖ 70B model loads and infers (multi-memory)
- ‚úÖ Latency <100ms/token for 7B on modern CPU
- ‚úÖ Fused kernels implemented and benchmarked
- ‚úÖ Documentation complete with examples
- ‚úÖ CI tests passing for memory64 builds

---

## üó∫Ô∏è Phase 2 Timeline

| Week | Focus | Deliverables |
|------|-------|--------------|
| **Week 1** | Memory64 foundation | 7B model working in Wasmtime |
| **Week 2** | Multi-memory sharding | 70B model loading, basic inference |
| **Week 3** | Fused kernels + optimization | <100ms/token for 7B, benchmarks |

**Total**: 3 weeks to production-ready large model support.

---

## üöÄ Next Steps

1. **Immediate**: Research current Rust wasm64 target status (may need nightly)
2. **Week 1 Start**: Set up Wasmtime dev environment, test memory64 API
3. **Week 1 End**: Load 7B model, measure baseline performance
4. **Week 2 Start**: Implement multi-memory manager
5. **Week 2 End**: 70B model inference working (even if slow)
6. **Week 3**: Optimize with fused kernels, hit performance targets

---

**Ready to begin Phase 2 implementation?** üéØ

Let me know which component to start with:
- A) Memory64 build setup
- B) Multi-memory manager design
- C) Fused kernel prototypes
- D) All of the above in parallel

---

*Created: 2025-10-16*
*Phase: 2 Planning*
*Status: üß† Ultrathink Complete - Ready for Implementation*
